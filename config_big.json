{
  "tokenizer": {
    "vocab_size": 37000
  },
  "model": {
    "N": 6,
    "d_model": 1024,
    "d_ff": 4096,
    "h": 16,
    "d_k": 64,
    "d_v": 64,
    "p_drop": 0.3
  },
  "trainer": {
    "batch_size": 16,
    "max_epochs": 60,
    "precision": 16,
    "accumulate_grad_batches": 8
  },
  "optimizer": {
    "learning_rate": 0.0001,
    "eps": 1e-9,
    "beta_1": 0.9,
    "beta_2": 0.98
  },
  "loss": {
    "label_smoothing": 0.1
  },
  "scheduler": {
    "warmup_steps": 4000
  },
  "beam_search": {
    "beam_size": 4,
    "max_len_factor": 50,
    "alpha": 0.6
  }
}