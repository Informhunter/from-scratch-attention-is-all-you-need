{
  "tokenizer": {
    "vocab_size": 37000
  },
  "model": {
    "N": 6,
    "d_model": 512,
    "d_ff": 2048,
    "h": 8,
    "d_k": 64,
    "d_v": 64,
    "p_drop": 0.1,
    "max_len": 512,
    "checkpoint_gradients": false
  },
  "dataset": {
    "batch_size": 2500,
    "maxi_batch_size": 1000,
    "max_len": 250
  },
  "trainer": {
    "max_epochs": 240,
    "precision": 16,
    "accumulate_grad_batches": 1,
    "val_check_interval": 0.1,
    "num_sanity_val_checks": 0,
    "save_last_k_checkpoints": 10,
    "save_best_k_checkpoints": 10
  },
  "optimizer": {
    "learning_rate": 0.0001,
    "eps": 1e-9,
    "beta_1": 0.9,
    "beta_2": 0.98
  },
  "loss": {
    "label_smoothing": 0.1
  },
  "scheduler": {
    "type": "vanilla",
    "warmup_steps": 4000
  },
  "beam_search": {
    "beam_size": 4,
    "max_len_factor": 50,
    "alpha": 0.6
  },
  "train_dataloader": {
    "num_workers": 16,
    "prefetch_factor": 2
  },
  "val_dataloader": {
    "num_workers": 16,
    "prefetch_factor": 2,
    "batch_size": 8
  }
}
